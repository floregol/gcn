\documentclass{article}
\usepackage[top=1.2in, bottom=1in, left=0.9in, right=0.9in]{geometry}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{gensymb}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[parfill]{parskip}
\usepackage[makeroom]{cancel}
\usepackage[section]{placeins}
\usepackage{fancyhdr}
%\usepackage{fourier}
\usepackage{appendix}
\usepackage{pdflscape}
\usepackage{datetime}
\usepackage[utf8]{inputenc}
\usepackage{tocloft}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage{booktabs}
\usepackage{mwe}
\usepackage{lipsum}
\usepackage{booktabs}
\usepackage{fancyhdr}
\usepackage{appendix}
\usepackage{datetime}
\usepackage{url}
\usepackage{siunitx}
\usepackage{verbatimbox}
\usepackage{lmodern}
\usepackage{blindtext}
\usepackage{natbib}

\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\begin{document}
\bibliographystyle{plainnat}
		
	\begin{center}

		\textsc{\huge Subsampled GCNN}\\[0.5cm] 
		\textsc{\large Florence Robert-Regol \hfill THE GREAT Jonas Scheller  \hfill Mark Coates}\\
		\textsc{\today}\\[0.5cm] 
		
	\end{center}


\pagestyle{fancy}
\lhead{Sampled Graph Convolutional Neural Networks}
\rhead{\today}
\pagenumbering{arabic}

\section*{Objective}
Problem formulation:

Classify graph-structured data where the topology(todo check if this is right words) is fully known, but  the labels and features of some nodes are missing. During training, the information of a selected subset of unknown nodes can be obtained.\

Solution:

Extend the existing GCNN model introduced by \citet{kipf2017semi}
 to be able to train without having all the features known and use greedy sampling methods from \citet{DBLP:journals/corr/ChamonR17}
 to select which unknown node would be more helpful to get better results. \
 
1. First the GCNN extension with some experiments is presented. 2. Greedy sampling algorithm  
3. Merging of the two.

\section*{GCNN}
\subsection*{Review of Previous Work}
The first step of this work was to reproduce the results obtained by \citet{kipf2017semi} using the same two layers graph convolutional neural network.

\begin{equation}
Z = f(X, A) = softmax(\text{\^{A}} ReLU(\text{\^{A}}XW_0))W_1))
\end{equation}

where \^{A} is an augmented and normalized adjacency matrix defined as
\begin{equation}
\text{\^{A}} = \text{\~{D}}^{-1/2}\text{\~{A}}\text{\~{D}}^{-1/2}
\end{equation}

In figure \ref{repro}, the blue line is is the results obtained by the experiment and the black point is the result reported in the paper. We can conclude that the results were successfully reproduced.

\begin{figure}[h]
\centering
\includegraphics[scale=0.8]{reproducibility_experiment}
\caption{Test Accuracy for GCNN in asemi-supervised settings for the Cora dataset}
\label{repro}
\end{figure}
\subsection*{GCNN extension}
To be able to train without the complete feature set, some adjustments needed to be made in the algorithm. The goal is to nullify the contribution of a sampled-out node to his neighbors without interfering with the opposing mechanism by which the node with unknown feature pulls information from his neighbors.
\\
To do so, the adjacency matrix at the first layer is altered by setting the column of sampled-out nodes to zero.
\begin{equation}
Z = f(X, A) = softmax(\text{\^{A}} ReLU(\text{\^{A}}_{sampled}XW_0))W_1))
\end{equation}

This way, only the existing information is propagated and is not diluted by the unknown at the first convolution stage. At the second stage, this mechanism assumes that every node can be used ant the normal adjacency matrix is used. 
\\This could be fixed by a second analysis of the graph in which nodes who couldn't not be reached by the first convolution (only connected to other unknown) would also have their column set to zero.
%TODO do it
TODO do it
\subsection*{Experiments}
Unless otherwise stated, all experiments were conducted using the Cora dataset, with the same testing/training/validation ratio of $37\%/45\%/18\%$. The black point is the reported result from \citeauthor{kipf2017semi} as a reference.
\subsubsection*{Sampled GCNN vs GCNN}
The first experiment is a comparison of the initial GCNN with the new sampled GCNN model, from which not only the labels are missing but also the features \ref{with_test_balanced}. To be able to compare the two, the labels balance was kept and the testing and validation features were not remove for both models. 

\begin{figure}[h]
\centering
\includegraphics[scale=0.8]{GCNNvs_with_test}
\caption{
Experiment 1
}
\label{with_test_balanced}
\end{figure}

The same experiment was made but without the testing and validation features known, for both model \ref{without_test_balanced}. This problem setting is more aligned with the goal of this project.

Considering the testing/validation vs training ratio, this is a significant reduction of available information during training. However, the sampled model was much more affected than the normal GCNN by this additional restriction. The normal GCNN only looked like it took a drop of 5\% but the overall shape of the curve seems unaffected, whereas the accurcay of the sampled GCNN took a more important drop 

\begin{figure}[h]
\centering
\includegraphics[scale=0.8]{GCNNvs_without_test}
\caption{
Experiment 2
}
\label{without_test_balanced}
\end{figure}


%TODO
1.This could indicate that features are highly correlated to the labeling and that few examples are needed. -> Could be verified by running a simple neural network todo
2. Graph connectivity is too sparse and with that little known node as 10-30\%, information can't travel with only two hops and has trouble reaching some nodes. -> Check the topology of misclassified node, how far they are from known ones. todo
3. The second layer adjacency matrix simplification is bad todo

               
\subsubsection*{Unbalanced Labels}
In the previous tests, to be consistent with the experiment conducted in the paper, the label balance was maintained thorough the experiment (Except for the 100\% case where every label was included). This is the same experiments but without label balance maintained. Figure \ref{with_test_unbalanced} and figure \ref{without_test_unbalanced} look pretty similar to their corresponding balanced version, respectively figure \ref{with_test_balanced} and figure \ref{without_test_balanced}.

\begin{figure}[h]
\centering
\includegraphics[scale=0.8]{GCNNvs_with_random}
\caption{
Experiment 3
}
\label{with_test_unbalanced}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[scale=0.8]{GCNNvs_without_test_random}
\caption{
Experiment 4
}
\label{without_test_unbalanced}
\end{figure}

\subsubsection*{Identity Features}
The last experiment was to replace the feature matrix by an identity matrix, making the identity of the nodes the only information accessible to the GCNN. The results were compared to the balanced results from figure \ref{with_test_balanced} and figure \ref{without_test_balanced}. In the case of with testing and validation features known, the identity matrix seems to suffer a relatively constant loss of around 7\%. A uprising result is that in the case of removed testing and validatin feaetures, the sampled GCNN performed worst than sampled GCNN with identity features. This could maybe be explained by the wrong second layer adjacency matrix(?).

\begin{figure}[h]
\centering
\includegraphics[scale=0.8]{GCNNvs_with_test_Identity}
\caption{
Experiment 5
}
\label{with_test_balanced_Iden}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[scale=0.8]{GCNNvs_without_test_Identity}
\caption{
Experiment 6
}
\label{without_test_balanced_Iden}
\end{figure}


\section*{Greedy Sampling}
\subsection*{Review of Previous Work}

TODO present the greedy algorithm

\subsection*{Extension}
TODO extends x to multidimensional input (ask mark)
\section*{Final algorithm}
TODO define H as a linear version of GCNN (?)
\section*{Results}
it works well
\bibliography{literature}{}

\end{document}
